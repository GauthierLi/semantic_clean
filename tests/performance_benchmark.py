#!/usr/bin/env python3
"""
æ‰¹é‡ç‰¹å¾æå–æ€§èƒ½åŸºå‡†æµ‹è¯•
è¯¦ç»†æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°ä¸‹çš„æ€§èƒ½è¡¨ç°å’Œå†…å­˜ä½¿ç”¨æƒ…å†µ
"""

import os
import sys
import time
import psutil
import numpy as np
import cv2
import torch
from typing import List
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from image_serialize.feature_extractor import DINOv3FeatureExtractor

def create_test_images(num_images: int = 100) -> List[np.ndarray]:
    """åˆ›å»ºæµ‹è¯•å›¾ç‰‡"""
    images = []
    for i in range(num_images):
        # åˆ›å»ºä¸åŒé¢œè‰²çš„æµ‹è¯•å›¾ç‰‡
        color = np.random.randint(0, 255, size=3)
        image = np.full((256, 256, 3), color, dtype=np.uint8)
        # æ·»åŠ éšæœºå™ªå£°ä½¿å›¾ç‰‡æœ‰æ‰€åŒºåˆ«
        noise = np.random.randint(0, 50, size=(256, 256, 3))
        image = np.clip(image.astype(int) + noise, 0, 255).astype(np.uint8)
        images.append(image)
    return images

def measure_memory_usage():
    """æµ‹é‡å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

def benchmark_batch_sizes():
    """æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°çš„æ€§èƒ½"""
    print("=== æ‰¹é‡å¤§å°æ€§èƒ½åŸºå‡†æµ‹è¯• ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_images = create_test_images(50)
    batch_sizes = [1, 4, 8, 16, 32, 64]
    
    results = {
        'batch_size': [],
        'time': [],
        'memory_peak': [],
        'throughput': []
    }
    
    for batch_size in batch_sizes:
        print(f"\næµ‹è¯•æ‰¹é‡å¤§å°: {batch_size}")
        
        # é‡ç½®æ¨¡å‹ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒ
        extractor = DINOv3FeatureExtractor(batch_size=batch_size)
        
        # æµ‹é‡åˆå§‹å†…å­˜
        initial_memory = measure_memory_usage()
        peak_memory = initial_memory
        
        # æ‰§è¡Œç‰¹å¾æå–
        start_time = time.time()
        
        try:
            features = extractor.extract_features_batch(test_images)
            execution_time = time.time() - start_time
            
            # æµ‹é‡å³°å€¼å†…å­˜
            current_memory = measure_memory_usage()
            peak_memory = max(peak_memory, current_memory)
            
            # è®¡ç®—ååé‡ï¼ˆå›¾ç‰‡/ç§’ï¼‰
            throughput = len(test_images) / execution_time
            
            results['batch_size'].append(batch_size)
            results['time'].append(execution_time)
            results['memory_peak'].append(peak_memory - initial_memory)
            results['throughput'].append(throughput)
            
            print(f"  æ‰§è¡Œæ—¶é—´: {execution_time:.4f}s")
            print(f"  å†…å­˜å¢é•¿: {peak_memory - initial_memory:.2f}MB")
            print(f"  ååé‡: {throughput:.2f} å›¾ç‰‡/ç§’")
            
        except Exception as e:
            print(f"  é”™è¯¯: {e}")
            continue
    
    return results

def compare_individual_vs_batch():
    """æ¯”è¾ƒé€ä¸ªå¤„ç†ä¸æ‰¹é‡å¤„ç†çš„æ€§èƒ½"""
    print("\n=== é€ä¸ªå¤„ç† vs æ‰¹é‡å¤„ç†æ€§èƒ½å¯¹æ¯” ===")
    
    test_images = create_test_images(20)
    
    # é€ä¸ªå¤„ç†
    extractor_individual = DINOv3FeatureExtractor(batch_size=1)
    
    initial_memory = measure_memory_usage()
    start_time = time.time()
    
    individual_features = []
    for image in test_images:
        feature = extractor_individual.extract_features(image)
        individual_features.append(feature.cpu().numpy())
    
    individual_time = time.time() - start_time
    individual_memory = measure_memory_usage() - initial_memory
    
    print(f"é€ä¸ªå¤„ç†:")
    print(f"  æ—¶é—´: {individual_time:.4f}s")
    print(f"  å†…å­˜å¢é•¿: {individual_memory:.2f}MB")
    
    # æ‰¹é‡å¤„ç†ï¼ˆä¸åŒæ‰¹é‡å¤§å°ï¼‰
    for batch_size in [4, 8, 16, 32]:
        extractor_batch = DINOv3FeatureExtractor(batch_size=batch_size)
        
        initial_memory = measure_memory_usage()
        start_time = time.time()
        
        batch_features = extractor_batch.extract_features_batch(test_images)
        
        batch_time = time.time() - start_time
        batch_memory = measure_memory_usage() - initial_memory
        
        speedup = individual_time / batch_time
        
        print(f"æ‰¹é‡å¤„ç† (batch_size={batch_size}):")
        print(f"  æ—¶é—´: {batch_time:.4f}s")
        print(f"  å†…å­˜å¢é•¿: {batch_memory:.2f}MB")
        print(f"  æ€§èƒ½æå‡: {speedup:.2f}x")
        print(f"  å†…å­˜æ•ˆç‡: {individual_memory/batch_memory:.2f}x")

def test_scalability():
    """æµ‹è¯•å¯æ‰©å±•æ€§"""
    print("\n=== å¯æ‰©å±•æ€§æµ‹è¯• ===")
    
    # æµ‹è¯•ä¸åŒæ•°æ®é‡çš„å¤„ç†æ—¶é—´
    image_counts = [10, 25, 50, 100]
    batch_size = 16
    
    for count in image_counts:
        test_images = create_test_images(count)
        extractor = DINOv3FeatureExtractor(batch_size=batch_size)
        
        start_time = time.time()
        features = extractor.extract_features_batch(test_images)
        execution_time = time.time() - start_time
        
        throughput = count / execution_time
        print(f"å›¾ç‰‡æ•°é‡: {count}, æ—¶é—´: {execution_time:.4f}s, ååé‡: {throughput:.2f} å›¾ç‰‡/ç§’")

def generate_performance_report(results):
    """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
    print("\n=== æ€§èƒ½æ€»ç»“æŠ¥å‘Š ===")
    
    # æ‰¾åˆ°æœ€ä½³æ‰¹é‡å¤§å°
    best_idx = np.argmax(results['throughput'])
    best_batch_size = results['batch_size'][best_idx]
    best_throughput = results['throughput'][best_idx]
    
    print(f"æœ€ä½³æ‰¹é‡å¤§å°: {best_batch_size}")
    print(f"æœ€é«˜ååé‡: {best_throughput:.2f} å›¾ç‰‡/ç§’")
    
    # è®¡ç®—æ€§èƒ½æå‡å€æ•°
    baseline_throughput = results['throughput'][0]  # batch_size=1
    speedup = best_throughput / baseline_throughput
    print(f"ç›¸æ¯”é€ä¸ªå¤„ç†çš„æ€§èƒ½æå‡: {speedup:.2f}x")
    
    # å†…å­˜æ•ˆç‡åˆ†æ
    baseline_memory = results['memory_peak'][0]
    best_memory = results['memory_peak'][best_idx]
    memory_efficiency = baseline_memory / best_memory if best_memory > 0 else 1.0
    print(f"ç›¸æ¯”é€ä¸ªå¤„ç†çš„å†…å­˜æ•ˆç‡: {memory_efficiency:.2f}x")

def main():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("å¼€å§‹æ‰¹é‡ç‰¹å¾æå–æ€§èƒ½åŸºå‡†æµ‹è¯•...\n")
    
    try:
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        results = benchmark_batch_sizes()
        
        # æ¯”è¾ƒé€ä¸ªå¤„ç†ä¸æ‰¹é‡å¤„ç†
        compare_individual_vs_batch()
        
        # æµ‹è¯•å¯æ‰©å±•æ€§
        test_scalability()
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        if results['batch_size']:
            generate_performance_report(results)
        
        print("\nğŸ‰ æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()